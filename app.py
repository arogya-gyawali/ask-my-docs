import streamlit as st
import chromadb
from pathlib import Path
from rag_pipeline import ask_my_docs, retrieve_context

# --- PAGE CONFIG ---
st.set_page_config(page_title="Ask My Docs üß†", page_icon="üß†", layout="wide")

# --- INITIAL SETUP ---
DB_DIR = Path("db")
COLLECTION_NAME = "documents"

try:
    chroma_client = chromadb.PersistentClient(path=str(DB_DIR))
    collection = chroma_client.get_or_create_collection(COLLECTION_NAME)
    num_docs = collection.count()
except Exception as e:
    st.error(f"‚ùå Could not connect to ChromaDB: {e}")
    st.stop()

# --- SIDEBAR ---
st.sidebar.header("üìÇ Project Info")
st.sidebar.markdown("**Ask My Docs** ‚Äî Local RAG assistant using Ollama + ChromaDB.")
st.sidebar.markdown(f"üìÑ **Indexed Chunks:** `{num_docs}`")
st.sidebar.markdown(f"üíæ **Database Path:** `{DB_DIR.resolve()}`")
st.sidebar.markdown("üß† **Models:**\n- `nomic-embed-text`\n- `llama3.1:8b`")
st.sidebar.divider()
st.sidebar.markdown("üí¨ Type a question below to get started!")

# --- MAIN CHAT AREA ---
st.title("üß† Ask My Docs ‚Äî Local Chat Assistant")
st.caption("Chat with your PDFs locally. 100% offline. Zero cloud, zero cost.")

if num_docs == 0:
    st.warning("‚ö†Ô∏è No documents indexed yet. Please run `ingest.py` first.")
    st.stop()

# --- SESSION STATE (persistent chat history) ---
if "history" not in st.session_state:
    st.session_state.history = []

# --- DISPLAY PREVIOUS CHAT HISTORY ---
for q, a in st.session_state.history:
    with st.chat_message("user"):
        st.markdown(q)
    with st.chat_message("assistant"):
        st.markdown(a)

# --- CHAT INPUT ---
query = st.chat_input("Ask a question about your documents...")

if query:
    # Only append new query if it‚Äôs different from the last one
    if not st.session_state.history or st.session_state.history[-1][0] != query:
        with st.chat_message("user"):
            st.markdown(query)

        with st.spinner("üí≠ Thinking..."):
            try:
                answer = ask_my_docs(query)
            except Exception as e:
                st.error(f"‚ö†Ô∏è Model error: {e}")
                st.stop()

        st.session_state.history.append((query, answer))

        with st.chat_message("assistant"):
            st.markdown(answer)

# --- DEBUG MODE ---
with st.expander("üß© Show Retrieved Context (Debug Mode)"):
    if st.session_state.history:
        last_query = st.session_state.history[-1][0]
        try:
            docs, metas = retrieve_context(last_query)
            st.subheader("üìÑ Retrieved Chunks:")
            for m, d in zip(metas, docs):
                st.markdown(f"**{m['filename']}** (chunk {m['chunk_index']}):")
                st.code(d[:600] + ("..." if len(d) > 600 else ""), language="markdown")
        except Exception as e:
            st.error(f"‚ö†Ô∏è Failed to fetch context: {e}")
